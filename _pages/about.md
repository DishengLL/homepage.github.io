---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a PhD candidate in Computer Science at Case Western Reserve University (CWRU), where I am advised by Prof. Yu Yin.

Prior to that, I was a Visiting student at ShanghaiTech University. I received my M.S. in Information Science from University of Pittsburgh (Pitt) in 2022. I received my B.Eng. in Computing and Information Science from Guangdong University of Technology supervised by Prof. Weihua He.

I have broad research interests in **Computer Vision** and **Vision-Language Models**, with a particular focus on advancing **spatial intelligence** in the next generation of AI systems. (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=xlIBwREAAAAJ&hl=en'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìö Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='/images/Project/Spatial_VLM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Spatial Intelligence in Vision-Language Models: A Comprehensive Survey**](https://www.techrxiv.org/doi/full/10.36227/techrxiv.176231405.57942913/v2)

**Disheng Liu**, Tuo Liang, Zhe Hu, Jierui Peng, Yiren Lu, Yi Xu, Yun Fu, Yu Yin

[**Github**](https://github.com/vulab-AI/Awesome-Spatial-VLMs) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Vision-Language Models (VLMs) have achieved great success but still lack spatial intelligence, and this survey provides the first unified overview of recent advances, taxonomies, and evaluations toward building spatially intelligent AI.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='/images/Project/Synthetic.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Balancing Fidelity and Diversity: Synthetic data could stand on the shoulder of the real in visual recognition**](https://arxiv.org/pdf/2503.04852)

**Disheng Liu**, Tuo Liang, Yu Yin

[**Github**](https://github.com/DishengLL/BALANCING-FIDELITY-AND-DIVERSITY) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='/images/Project/Causal3D.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data**](https://arxiv.org/pdf/2503.04852)

**Disheng Liu\***, Yiran Qiao\*, Wuche Liu, Yiren Lu, Yunlai Zhou, Tuo Liang, Yu Yin, Jing Ma  
\*Equal contribution

[**Datasets**](https://huggingface.co/datasets/LLDDSS/Causal3D_Dataset) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- True intelligence relies on understanding hidden causal relations, yet current AI and vision models lack benchmarks to assess this ability. We introduce Causal3D, a comprehensive 19-dataset benchmark linking structured and visual data to evaluate causal reasoning, revealing that performance drops sharply as causal complexity increases.
</div>
</div>

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üè´ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Working Experience
<!-- - *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->


# üìù Servicing 
Reviewer for

ICLR'26, CVPR'26

# üéì Teaching
Teaching Assistant

‚Ä¢	Fall 2025 ‚Äî CSDS 465: Computer Vision (Instructor: Yu Yin)

‚Ä¢	Spring 2025 ‚Äî CSDS 425: Computer Networks (Instructor: An Wang)

‚Ä¢	Fall 2024 ‚Äî CSDS 425: Computer Networks (Instructor: Mark Allman)